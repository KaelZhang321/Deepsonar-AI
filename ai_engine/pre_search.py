"""
PreSearch Module - Multi-Source Search with Fallback

This module implements a pre-search strategy that fetches search results
BEFORE the crew runs, injecting them into task descriptions.

Search Priority:
1. Tavily (primary) - optimized for AI agents
2. Bocha (fallback) - Chinese search with AI answers

This bypasses CrewAI's tool calling mechanism which has compatibility
issues with certain LLM APIs (like Volcengine ARK).
"""
import os
import requests
from typing import Optional


def pre_search(query: str, count: int = 20) -> dict:
    """
    Perform a robust AI search before crew execution.
    
    Search Priority:
    1. Tavily Search API (if TAVILY_API_KEY configured)
    2. Bocha AI Search (fallback)
    
    Args:
        query: The search query
        count: Number of results to fetch
        
    Returns:
        Dict with search_results (formatted string), references (list), 
        raw_data (list), and search_source (str)
    """
    # Try Tavily first (higher priority)
    tavily_result = _try_tavily_search(query, count)
    if tavily_result.get("raw_data"):
        print(f"âœ… Tavily search returned {len(tavily_result['raw_data'])} results")
        return tavily_result
    
    # Fallback to Bocha
    print("âš ï¸ Tavily search failed or returned no results, falling back to Bocha...")
    bocha_result = _try_bocha_search(query, count)
    return bocha_result


def _try_tavily_search(query: str, count: int) -> dict:
    """
    Try searching with Tavily API.
    
    Returns:
        Dict with search results or empty dict on failure
    """
    try:
        from ai_engine.tavily_api import tavily_search, parse_tavily_response
        
        api_key = os.getenv("TAVILY_API_KEY")
        if not api_key:
            print("âš ï¸ TAVILY_API_KEY not configured, skipping Tavily search")
            return {"search_results": "", "references": [], "raw_data": []}
        
        print(f"ğŸ” Trying Tavily search for: {query[:50]}...")
        
        raw_response = tavily_search(
            query,
            max_results=min(count, 20),
            search_depth="advanced",
            include_answer=True,
            api_key=api_key
        )
        
        if not raw_response.get("success"):
            print(f"âš ï¸ Tavily search failed: {raw_response.get('error', 'Unknown error')}")
            return {"search_results": "", "references": [], "raw_data": []}
        
        parsed = parse_tavily_response(raw_response)
        web_sources = parsed.get("web_sources", [])
        ai_answer = parsed.get("answer", "")
        
        if not web_sources and not ai_answer:
            return {"search_results": "", "references": [], "raw_data": []}
        
        return _format_search_results(web_sources, ai_answer, query, "tavily")
        
    except Exception as e:
        print(f"âš ï¸ Tavily search exception: {e}")
        return {"search_results": "", "references": [], "raw_data": []}


def _try_bocha_search(query: str, count: int) -> dict:
    """
    Try searching with Bocha API (fallback).
    
    Returns:
        Dict with search results
    """
    try:
        from ai_engine.bocha_api import bocha_ai_search, parse_bocha_response
        
        print(f"ğŸ” Trying Bocha search for: {query[:50]}...")
        
        raw_response = bocha_ai_search(
            query, 
            count=count, 
            answer=True,
            stream=False
        )
        
        parsed = parse_bocha_response(raw_response)
        web_sources = parsed.get("web_sources", [])
        ai_answer = parsed.get("answer", "")
        
        if not web_sources and not ai_answer:
            return {
                "search_results": f"æœªæ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„æœç´¢ç»“æœã€‚è¯·åŸºäºæ‚¨çš„ä¸“ä¸šçŸ¥è¯†è¿›è¡Œåˆ†æã€‚",
                "references": [],
                "raw_data": [],
                "search_source": "none"
            }
        
        return _format_search_results(web_sources, ai_answer, query, "bocha")
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "search_results": f"æœç´¢å¤±è´¥ï¼š{str(e)}ã€‚è¯·åŸºäºæ‚¨çš„ä¸“ä¸šçŸ¥è¯†è¿›è¡Œåˆ†æã€‚",
            "references": [],
            "raw_data": [],
            "search_source": "error"
        }


def _format_search_results(web_sources: list, ai_answer: str, query: str, source: str) -> dict:
    """
    Format search results into a standardized structure.
    
    Args:
        web_sources: List of webpage results
        ai_answer: AI-generated answer/summary
        query: Original search query
        source: Search source name (tavily/bocha)
        
    Returns:
        Formatted dict with search_results, references, raw_data, search_source
    """
    results = []
    references = []
    raw_data = []
    
    # Add AI Answer as the first "source" of insight
    if ai_answer:
        results.append(
            "ã€AI æ™ºèƒ½ç»¼è¿°ã€‘\n"
            f"{ai_answer}\n"
        )
    
    for i, page in enumerate(web_sources, 1):
        ref_id = f"[Ref-{i}]"
        # Handle both Tavily (name) and Bocha (name) field names
        title = page.get("name", page.get("title", "æ— æ ‡é¢˜"))
        snippet = page.get("snippet", page.get("content", ""))
        url = page.get("url", "")
        
        # Truncate snippet for context management
        short_snippet = snippet[:350] + "..." if len(snippet) > 350 else snippet
        
        results.append(
            f"æ¥æº {ref_id}\n"
            f"æ ‡é¢˜: {title}\n"
            f"å†…å®¹: {short_snippet}\n"
            f"é“¾æ¥: {url}"
        )
        
        references.append(f"{ref_id} {title}, é“¾æ¥: {url}")
        
        raw_data.append({
            "ref_id": ref_id,
            "title": title,
            "snippet": snippet,
            "url": url
        })
    
    search_results = "\n\n---\n\n".join(results)
    
    return {
        "search_results": search_results,
        "references": references,
        "raw_data": raw_data,
        "search_source": source
    }


def format_research_data(topic: str, search_data: dict) -> str:
    """
    Format search data into a research context for tasks.
    
    Args:
        topic: The research topic
        search_data: Dict from pre_search()
        
    Returns:
        Formatted research context string
    """
    source_name = search_data.get("search_source", "unknown")
    output = f"## ã€Œ{topic}ã€ç›¸å…³æœç´¢èµ„æ–™ï¼ˆå…± {len(search_data['references'])} æ¡çœŸå®æ¥æºï¼Œæ¥è‡ª {source_name.upper()}ï¼‰\n\n"
    output += "ã€é‡è¦è­¦å‘Šã€‘ä»¥ä¸‹æ˜¯çœŸå®çš„æœç´¢ç»“æœå’ŒURLï¼ŒæŠ¥å‘Šä¸­å¿…é¡»ä½¿ç”¨è¿™äº›çœŸå®é“¾æ¥ï¼Œç¦æ­¢ç¼–é€ å‡é“¾æ¥ï¼\n\n"
    output += search_data["search_results"]
    output += "\n\n---\n\n## ã€å¿…é¡»ä½¿ç”¨çš„å‚è€ƒæ–‡çŒ®ã€‘ï¼ˆçœŸå®URLï¼Œç¦æ­¢ä¿®æ”¹ï¼‰\n\n"
    for ref in search_data["references"]:
        output += f"- {ref}\n"
    output += "\nã€å¼ºåˆ¶è¦æ±‚ã€‘æŠ¥å‘Šç»“å°¾çš„å‚è€ƒæ–‡çŒ®å¿…é¡»åŸæ ·å¤åˆ¶ä¸Šè¿°åˆ—è¡¨ï¼Œä¸å¾—ç¼–é€  example.com ç­‰å‡é“¾æ¥ï¼\n"
    
    return output


def save_search_to_db(keyword: str, search_data: dict, report=None):
    """
    Save search results to database with optional report association.
    
    Args:
        keyword: The search keyword
        search_data: Dict containing raw_data, search_results, references, search_source
        report: Optional Report instance to associate with the search result
    """
    try:
        import sys
        from pathlib import Path
        
        backend_dir = Path(__file__).resolve().parent.parent / "backend"
        if str(backend_dir) not in sys.path:
            sys.path.insert(0, str(backend_dir))
        
        os.environ.setdefault("DJANGO_SETTINGS_MODULE", "config.settings")
        
        import django
        if not django.apps.apps.ready:
            django.setup()
        
        from apps.reports.models import SearchResult
        
        formatted = f"å…³é”®è¯: {keyword}\n\n{search_data['search_results']}"
        search_source = search_data.get("search_source", "bocha")
        
        SearchResult.objects.create(
            keyword=keyword,
            report=report,
            results_count=len(search_data["raw_data"]),
            results_json=search_data["raw_data"],
            formatted_results=formatted,
            search_source=search_source
        )
    except Exception as e:
        print(f"Database save error: {e}")
